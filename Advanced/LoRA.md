# 再谈微调技术：LoRA

## 背景

我们在基础篇《大语言模型：通往通用人工智能之路》中提到**两阶段训练法**， 即**预训练**（Pre-Train)和**微调**(Fine Tune)。
在本章中，我们讲详细聊聊其中的SFT部分。而站在2024年的时间节点上，其中最重要的技术就是LoRA(Low-Rank Adaptation), 故本文将着重讲述LoRA技术。

## 提出问题

微调的含义，就是把已经训练好的模型（PTM, Pre-Train Model)拿来，用特定的下游任务数据来继续训练这个PTM，使得模型在预训练权重上继续更新权重，直至满足下游任务性能标准。

### 全量参数微调

**全量参数微调**指的是，在下游任务的训练中，对预训练模型的每一个参数都做更新。

而随着大语言模型的越来越大，全量参数微调的成本也越来越昂贵了。以ChatGPT3.5 175B 这种级别的LLM为例，世界上，没有几家公司能够支付的起日常的训练费用，一次训练费用需要百万美元以上。哪怕是小两个数量级，我们拿6B的LLM为例，全量参数微调也是非常昂贵的。
2024年，单机8卡（入门级别的显卡A6000）为例。一次全量参数训练，需要近1000小时。而一个含有LLM的软件到达产品发布级别的质量，要经过十轮以上的微调。除此之外，模型全量微调还会损失多样性，存在灾难性遗忘的问题。因此，在2024年，业界已经越来越少的采用全量参数微调了。

因此，我们就提出要解决的问题——如何高效的进行模型微调。

## 解决问题

如何高效的进行模型微调，成了业界研究的重点，发展出了很多种办法，这些方法统称**参数高效微调**（PEFT, Parameter-Efficient Fine-Tuning）。

### 参数高效微调

参数高效微调是指微调少量或额外的模型参数，固定大部分预训练模型(LLM)参数，从而大大降低了计算和存储成本，同时，也能实现与全量参数微调相当的性能，可以更好地泛化到域外场景。

高效微调技术可以粗略分为以下三大类：增加额外参数(Additive), 选取一部分参数更新(Selective)、引入重参数化(Reparametrization-based)。而在增加额外参数这类方法中，又主要分为类适配器(Adapter-like)方法和软提示(Soft prompts)两个小类。
下图中，把各种PEFT方法按照上述分类做了一个总结。
![LoRA_PEFT.png](../images/LoRA_PEFT.png)
目前，从效果来讲，增加额外参数(Additive)效果最好，LoRA也属于这一类中，如果从发展史来介绍各种代表性的算法，文章要写的很长。本文的重点是LoRA，所以笔者就介绍LoRA原论文里提及的两种算法，即Adapter-tuning和Prefix-tuning。

### Adapter-tuning

### Prefix-tuning

总结一下，​**全参数微调**太贵，**Adapter Tuning**存在训练和推理延迟，**Prefix Tuning**难训且会减少原始训练数据中的有效文字长度​，那是否有一种微调办法，能改善这些不足呢？

## LoRA


## 参考文献

1. [Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.15647)

