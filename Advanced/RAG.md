# 深入RAG：构造知识库

## 前言

这篇技术文章，笔者第一次用了“深入”这个词。此时的心情，类似于工作了十几年的资深技术人员，在简历里写了“精通某某技术”的感觉。学的越深，知道的越多，越不敢用这些修饰词。之所以，用上“深入”这个词。是觉得，在2025年当下，以及接下来的2~3年内，RAG对业界会有非常深远的影响，而一大堆聪明人不停的对这个技术进行迭代，使之焕发新春。对读者而言，希望务必搞懂RAG，打牢基础。

## RAG

### 提出问题

先抛开定义，我们先看看我们在运用LLM解决实际问题时，遇到了哪些”痛点“。
我们以最常见的AI智能客服（AI Chatbot）为例，最初的问题是对人类自然语言的理解不够好，后来随着LLM技术的发展，特别是BERT的大规模应用，已经很好的解决了这个问题，即NLU问题。接着，新的问题出现了，生成式LLM开始一本正经的胡说八道了，即产生了“幻觉”问题。如何解决这个“一本正经的胡说八道”问题呢？

### 解决问题

我们回到人类的场景，很多正式场合，比如外交部答记者问现场直播，是不允许发言人说错话的。这个时候，外交部发言人，往往手头都会有一份书面的文档，上面预先准备了大量的问题。发言人在回答记者问题是，需要先看一下手头的文件，然后回答记者的问题。用一个图来表示这个过程，如下图所示：
![RAG_human.svg](../images/RAG_human.svg)

现在我们把这个过程模拟到LLM技术中，来解决幻觉问题，即用LLM来代替人脑。
![RAG_sim.svg](../images/RAG_sim.svg)

其实，这就是RAG技术，其定义如下：
**RAG(Retrieval-Augmented Generation)** 是一种结合信息检索（Retrieval）和生成（Generation）的技术架构，主要用于构建智能问答系统或知识增强型生成任务。它通过检索外部知识库中的相关信息来增强生成模型的能力，从而提高生成结果的准确性和知识覆盖范围。

仔细观察上图，我们很容易得知RAG包含两个核心流程，一个是增强检索（Retrieval-Augmented)，另一个是生成(Generation)。现在，我们开始动手构造一个简单的RAG系统。

#### 简单的RAG系统

在打造RAG系统之前，需要先解决一个问题——如何构造文档？回到外交部发言人的例子，在正式开发布会前，需要花大量的精力准备记者的提问，也就是常见问题的答案集（FAQ）。同样的，在计算机系统里，我们也需要准备让LLM能读得懂的FAQ文档。这里，我们用向量来表示文档。如果读者想了解其中缘由，建议阅读之前的文章《词表达发展史》。



